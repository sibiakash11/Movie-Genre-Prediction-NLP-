{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~0123456789'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    plot = df.loc[i,'Plot']\n",
    "    tagged_sentence = nltk.tag.pos_tag(plot.split())\n",
    "    edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
    "    example_sentence = ' '.join(edited_sentence)\n",
    "    no_punct = \"\"\n",
    "    for char in example_sentence:\n",
    "       if char not in punctuations:\n",
    "           no_punct = no_punct + char\n",
    "       else:\n",
    "            no_punct += ' '\n",
    "    example_sentence = no_punct\n",
    "    tagged_sentence = nltk.tag.pos_tag(example_sentence.split())\n",
    "    edited_sentence = [word for word,tag in tagged_sentence if tag not in ['NNP','NNPS','NNS','NN']]\n",
    "#     print(len(edited_sentence))\n",
    "    example_sentence = ' '.join(edited_sentence)\n",
    "    example_sentence = example_sentence.lower()\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "    word_tokens = word_tokenize(example_sentence) \n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filt = [ps.stem(filtered_sentence[i]) for i in range(len(filtered_sentence))]\n",
    "    df.loc[i,'Plot_reduction'] = ' '.join(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('movie_info.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        work serv fill stereotyp irish burst insid ass...\n",
       "1        paint smile young walk past look smile embrac ...\n",
       "2        long compos two first sit tomb display three s...\n",
       "3        last consist two first set repres enthusiast h...\n",
       "4        earliest known classic show trade forc drop fr...\n",
       "                               ...                        \n",
       "34881    begin end centr around australian three serv m...\n",
       "34882                                          two describ\n",
       "34883    zafer coastal separ whose also help zafer marr...\n",
       "34884    centr around young name two separ abl go onto ...\n",
       "34885    iÌ‡stanbul mani help known write first novel fi...\n",
       "Name: Plot_reduction, Length: 34886, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Plot_reduction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('movie_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Plot_reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "      <td>work serv fill stereotyp irish burst insid ass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                   Title Origin/Ethnicity Director Cast  \\\n",
       "0          1901  Kansas Saloon Smashers         American  Unknown  NaN   \n",
       "\n",
       "     Genre                                          Wiki Page  \\\n",
       "0  unknown  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "\n",
       "                                                Plot  \\\n",
       "0  A bartender is working at a saloon, serving dr...   \n",
       "\n",
       "                                      Plot_reduction  \n",
       "0  work serv fill stereotyp irish burst insid ass...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    thriller = thriller[thriller['Plot_reduction']!= np.nan]\n",
    "    th_plot = thriller['Plot_reduction']\n",
    "    \n",
    "    th_plot = th_plot.append(pd.Series(summa,index = range(len(th_plot),len(th_plot)+len(summa))))\n",
    "    \n",
    "    th_plot = th_plot.dropna()\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df = 200,stop_words='english',max_df = 0.9,max_features = 500)\n",
    "    \n",
    "    bagofwords = vectorizer.fit_transform(th_plot)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = bagofwords.todense()\n",
    "    denselist = dense.tolist()\n",
    "    df2 = pd.DataFrame(denselist, columns=feature_names)\n",
    "    rat = df2.iloc[df.shape[0]-len(summa):]\n",
    "    rat = rat.T\n",
    "    rat.index.set_names(['words'],inplace = True)\n",
    "    \n",
    "    svd = TruncatedSVD(n_components = 1)\n",
    "    lsa = svd.fit_transform(bagofwords)\n",
    "    \n",
    "    diction30 = vectorizer.get_feature_names()\n",
    "    encoding_matrix = pd.DataFrame(svd.components_,index = ['Topic 1']).T\n",
    "    encoding_matrix['words'] = diction30\n",
    "    diction30 = encoding_matrix.sort_values(by=['Topic 1'],ascending = False)\n",
    "    diction30.index = diction30['words']\n",
    "    diction30 = diction30.drop(['words'],axis = 1)\n",
    "    \n",
    "    \n",
    "    comp = pd.concat([rat,diction30], axis=1, join='inner').T\n",
    "    c = cosine_similarity(comp,comp)\n",
    "    c[len(c[0])-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
